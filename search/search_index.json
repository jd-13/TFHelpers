{
    "docs": [
        {
            "location": "/",
            "text": "TFHelpers\n\n\nTFHelpers is a small collection of classes which implement common tasks in Tensorflow. The\nfunctionality provided by each module is described in this documentation.\n\n\nThe modules \nFilesAndLogging\n and \nTrainingHelpers\n provide functionality such as managing model\nfiles and early stopping, and may be useful in many tensorflow models. The module \nScikitWrapper\n\nprovides several classes which aid with implementing tensorflow models behind a scikit-learn style\nAPI.",
            "title": "Home"
        },
        {
            "location": "/#tfhelpers",
            "text": "TFHelpers is a small collection of classes which implement common tasks in Tensorflow. The\nfunctionality provided by each module is described in this documentation.  The modules  FilesAndLogging  and  TrainingHelpers  provide functionality such as managing model\nfiles and early stopping, and may be useful in many tensorflow models. The module  ScikitWrapper \nprovides several classes which aid with implementing tensorflow models behind a scikit-learn style\nAPI.",
            "title": "TFHelpers"
        },
        {
            "location": "/SKTFModels/",
            "text": "SKTFModels\n\n\nThis module provides examples of models built using the \nSciKitWrapper\n module. This is a good place\nto start if you wish to implement your own models using this wrapper.\n\n\nBasicRegressor\n\n\nCurrently this module provides only the \nBasicRegressor\n class, which inherits from \nTFRegressor\n\nand implements a basic multilayer feedforward network for regressions. Its hyperparameters are to be\npassed to the constructor as follows, and provide the following options:\n\n\nBasicRegressor(self,\n               learningRate=0.01,\n               batchSize=1000,\n               initializer=tf.contrib.layers.variance_scaling_initializer(),\n               dropoutRate=0.01,\n               restoreFrom=None,\n               hiddenNeuronsList=[10])\n\n\n\n\n\nlearningRate\n: Provided to the gradient descent algorithm, in this case \ntf.train.AdamOptimizer\n\n\nbatchSize\n: Number of rows of data to operate on at once\n\n\ninitializer\n: The initializer to use as the kernel initializer for each layer\n\n\ndropoutRate\n: Not yet implemented in this model, does nothing\n\n\nrestoreFrom\n: If this model has been trained previously with the same hyperparameters, provide\nthe date time string of the form YYYYMMDD-HHmm which corresponds to the previous training run. The\n\nCheckpointAndRestoreHelper\n will then look this up from the models directory.\n\n\nhiddenNeuronsList\n: A list of integers which describes the number of neurons in each hidden layer.\nEg. [100, 50, 30] would mean 100 neurons in the first layer, 50 in the second and 30 in the third\nlayer.",
            "title": "SKTFModels"
        },
        {
            "location": "/SKTFModels/#sktfmodels",
            "text": "This module provides examples of models built using the  SciKitWrapper  module. This is a good place\nto start if you wish to implement your own models using this wrapper.",
            "title": "SKTFModels"
        },
        {
            "location": "/SKTFModels/#basicregressor",
            "text": "Currently this module provides only the  BasicRegressor  class, which inherits from  TFRegressor \nand implements a basic multilayer feedforward network for regressions. Its hyperparameters are to be\npassed to the constructor as follows, and provide the following options:  BasicRegressor(self,\n               learningRate=0.01,\n               batchSize=1000,\n               initializer=tf.contrib.layers.variance_scaling_initializer(),\n               dropoutRate=0.01,\n               restoreFrom=None,\n               hiddenNeuronsList=[10])   learningRate : Provided to the gradient descent algorithm, in this case  tf.train.AdamOptimizer  batchSize : Number of rows of data to operate on at once  initializer : The initializer to use as the kernel initializer for each layer  dropoutRate : Not yet implemented in this model, does nothing  restoreFrom : If this model has been trained previously with the same hyperparameters, provide\nthe date time string of the form YYYYMMDD-HHmm which corresponds to the previous training run. The CheckpointAndRestoreHelper  will then look this up from the models directory.  hiddenNeuronsList : A list of integers which describes the number of neurons in each hidden layer.\nEg. [100, 50, 30] would mean 100 neurons in the first layer, 50 in the second and 30 in the third\nlayer.",
            "title": "BasicRegressor"
        },
        {
            "location": "/ScikitLearnWrapper/",
            "text": "Scikit-learn Wrapper\n\n\nTFHelpers provides a basic wrapper class which you can inherit from to create models which are\ncompatible with the scikit-learn api. Models which inherit from the \nSKTFWrapper\n class will be\ncompatible scikit-learn functionality such as \nGridSearchCV\n, and will provide \nfit\n and \npredict\n\nmethods for training and producing predictions.\n\n\nIf you inherit from \nSKTFWrapper\n you will need to build the graph and implement the the training\nloop in the \nfit\n method. The \nSciKitWrapper\n module also contains child classes of\n\nSKTFWrapper\n which provide further functionality. Currently only \nTFRegressor\n is available.\n\n\nTFRegressor\n\n\nIf you wish to create a regression model you can inherit from the \nTFRegressor\n class which provides\na lot of functionality, leaving the methods \n_buildGraph\n and \n_buildModelName\n for you to\nimplement.\n\n\nTFRegressor\n gives you the following features for free:\n\n\n\n\nA fairly conventional training loop, with user specified batch size\n\n\nLogging of training and validation losses to tensorboard on each epoch, as well as writing any \ntf.Summary\n nodes at each epoch\n\n\nSaving the model at each epoch\n\n\nContinuing training from previous runs\n\n\nSaving all model and tensorboard related files in separate directories, sorted by model hyperparameters and start time\n\n\nEarly stopping\n\n\nPredicted time to completion\n\n\nWarnings if parts of the graph do not appear to be training\n\n\n\n\nImplementation\n\n\n_buildGraph()\n\n\n\nIn this method you will need to build the graph for your model, and set the \nself._tensors\n\ndata member to a \nTFRegressorTensors\n object which contains the appropriate operations from your\ngraph. This object is the interface between the graph which you have created in \n_buildGraph\n and\nthe training loop implemented in \nTFRegressor\n.\n\n\n_buildModelName()\n\n\n\nIn this method you will need to return a string which adequately describes your model and its\nhyperparameters. This string is used to group model files.\n\n\nFor complete examples of both of the above methods, see \nSKTFModels.BasicRegressor\n.",
            "title": "Scikit-learn Wrapper"
        },
        {
            "location": "/ScikitLearnWrapper/#scikit-learn-wrapper",
            "text": "TFHelpers provides a basic wrapper class which you can inherit from to create models which are\ncompatible with the scikit-learn api. Models which inherit from the  SKTFWrapper  class will be\ncompatible scikit-learn functionality such as  GridSearchCV , and will provide  fit  and  predict \nmethods for training and producing predictions.  If you inherit from  SKTFWrapper  you will need to build the graph and implement the the training\nloop in the  fit  method. The  SciKitWrapper  module also contains child classes of SKTFWrapper  which provide further functionality. Currently only  TFRegressor  is available.",
            "title": "Scikit-learn Wrapper"
        },
        {
            "location": "/ScikitLearnWrapper/#tfregressor",
            "text": "If you wish to create a regression model you can inherit from the  TFRegressor  class which provides\na lot of functionality, leaving the methods  _buildGraph  and  _buildModelName  for you to\nimplement.  TFRegressor  gives you the following features for free:   A fairly conventional training loop, with user specified batch size  Logging of training and validation losses to tensorboard on each epoch, as well as writing any  tf.Summary  nodes at each epoch  Saving the model at each epoch  Continuing training from previous runs  Saving all model and tensorboard related files in separate directories, sorted by model hyperparameters and start time  Early stopping  Predicted time to completion  Warnings if parts of the graph do not appear to be training",
            "title": "TFRegressor"
        },
        {
            "location": "/ScikitLearnWrapper/#implementation",
            "text": "_buildGraph()  In this method you will need to build the graph for your model, and set the  self._tensors \ndata member to a  TFRegressorTensors  object which contains the appropriate operations from your\ngraph. This object is the interface between the graph which you have created in  _buildGraph  and\nthe training loop implemented in  TFRegressor .  _buildModelName()  In this method you will need to return a string which adequately describes your model and its\nhyperparameters. This string is used to group model files.  For complete examples of both of the above methods, see  SKTFModels.BasicRegressor .",
            "title": "Implementation"
        },
        {
            "location": "/TrainingHelpers/",
            "text": "TrainingHelpers\n\n\nClasses which provide functionality within the training loop of a tensorflow model.",
            "title": "TrainingHelpers"
        },
        {
            "location": "/TrainingHelpers/#traininghelpers",
            "text": "Classes which provide functionality within the training loop of a tensorflow model.",
            "title": "TrainingHelpers"
        },
        {
            "location": "/FilesAndLogging/",
            "text": "FilesAndLogging\n\n\nSeveral classes which assist with managing model files and creating tensorboard logs.",
            "title": "FilesAndLogging"
        },
        {
            "location": "/FilesAndLogging/#filesandlogging",
            "text": "Several classes which assist with managing model files and creating tensorboard logs.",
            "title": "FilesAndLogging"
        }
    ]
}